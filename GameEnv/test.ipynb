{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium \n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "import gymnasium\n",
    "import gymnasium_env\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "from gymnasium.spaces.utils import flatten_space\n",
    "import pprint\n",
    "from gymnasium import envs\n",
    "from gymnasium.wrappers import FlattenObservation\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "# Create environment\n",
    "env = gymnasium.make('gymnasium_env/slither_world')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys ['foodList', 'mySnake', 'mySnakeBody', 'otherSnakesList']\n",
      "shapes {'foodList': (600,), 'mySnake': (2,), 'mySnakeBody': (200,), 'otherSnakesList': (3000,)}\n",
      "dtypes {'foodList': dtype('float32'), 'mySnake': dtype('float32'), 'mySnakeBody': dtype('float32'), 'otherSnakesList': dtype('float32')}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Wrap the environment in a vectorized environment for faster training\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Initialize PPO model\n",
    "model = PPO(\n",
    "    policy = 'MultiInputPolicy',\n",
    "    env = env,\n",
    "    n_steps = 1024,\n",
    "    batch_size = 64,\n",
    "    n_epochs = 4,\n",
    "    gamma = 0.999,\n",
    "    gae_lambda = 0.98,\n",
    "    ent_coef = 0.01,\n",
    "    verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 145  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 7    |\n",
      "|    total_timesteps | 1024 |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 145           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 14            |\n",
      "|    total_timesteps      | 2048          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.0466194e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.00014340878 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.25e+08      |\n",
      "|    n_updates            | 4             |\n",
      "|    policy_gradient_loss | -7.49e-05     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 2.46e+08      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 140           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 21            |\n",
      "|    total_timesteps      | 3072          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6511261e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.00029921532 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.46e+08      |\n",
      "|    n_updates            | 8             |\n",
      "|    policy_gradient_loss | -7.96e-05     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 2.81e+08      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 139            |\n",
      "|    iterations           | 4              |\n",
      "|    time_elapsed         | 29             |\n",
      "|    total_timesteps      | 4096           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 7.935159e-06   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -2.84          |\n",
      "|    explained_variance   | -1.2516975e-05 |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 2.76e+08       |\n",
      "|    n_updates            | 12             |\n",
      "|    policy_gradient_loss | -0.000148      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 5.39e+08       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 140           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 36            |\n",
      "|    total_timesteps      | 5120          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2495085e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 3.0994415e-06 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.73e+08      |\n",
      "|    n_updates            | 16            |\n",
      "|    policy_gradient_loss | -9.25e-05     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 1.2e+09       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 143           |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 42            |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0551379e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.00028795004 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.06e+08      |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.000131     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 8.93e+08      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 145           |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 49            |\n",
      "|    total_timesteps      | 7168          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.093702e-06  |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 5.5849552e-05 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.77e+08      |\n",
      "|    n_updates            | 24            |\n",
      "|    policy_gradient_loss | -9.28e-05     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 3.6e+08       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 146           |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 55            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4572288e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.0017293692  |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.1e+08       |\n",
      "|    n_updates            | 28            |\n",
      "|    policy_gradient_loss | -5.44e-05     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 2.28e+08      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 146           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 62            |\n",
      "|    total_timesteps      | 9216          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.700077e-05  |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 2.9206276e-06 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.28e+08      |\n",
      "|    n_updates            | 32            |\n",
      "|    policy_gradient_loss | -0.000253     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 6.13e+08      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 146            |\n",
      "|    iterations           | 10             |\n",
      "|    time_elapsed         | 69             |\n",
      "|    total_timesteps      | 10240          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.3976824e-06  |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -2.84          |\n",
      "|    explained_variance   | -2.3841858e-07 |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 5.43e+08       |\n",
      "|    n_updates            | 36             |\n",
      "|    policy_gradient_loss | 6.73e-07       |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 1.12e+09       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 147           |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 76            |\n",
      "|    total_timesteps      | 11264         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5582191e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.0018631816  |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.17e+08      |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -4.31e-05     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 2.27e+08      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 146           |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 84            |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6878552e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 1.4364719e-05 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.81e+08      |\n",
      "|    n_updates            | 44            |\n",
      "|    policy_gradient_loss | -6.36e-05     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 8.01e+08      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 144            |\n",
      "|    iterations           | 13             |\n",
      "|    time_elapsed         | 92             |\n",
      "|    total_timesteps      | 13312          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 6.720831e-06   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -2.84          |\n",
      "|    explained_variance   | -7.1525574e-07 |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 7.36e+08       |\n",
      "|    n_updates            | 48             |\n",
      "|    policy_gradient_loss | -0.000127      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 1.45e+09       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 142            |\n",
      "|    iterations           | 14             |\n",
      "|    time_elapsed         | 100            |\n",
      "|    total_timesteps      | 14336          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 5.7325233e-06  |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -2.84          |\n",
      "|    explained_variance   | -1.1920929e-07 |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 1.19e+09       |\n",
      "|    n_updates            | 52             |\n",
      "|    policy_gradient_loss | -4.59e-05      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 2.42e+09       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 138           |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 110           |\n",
      "|    total_timesteps      | 15360         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4160912e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 1.1920929e-07 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.93e+09      |\n",
      "|    n_updates            | 56            |\n",
      "|    policy_gradient_loss | -9.29e-05     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 3.8e+09       |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 133            |\n",
      "|    iterations           | 16             |\n",
      "|    time_elapsed         | 123            |\n",
      "|    total_timesteps      | 16384          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.346576e-06   |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -2.84          |\n",
      "|    explained_variance   | -2.3841858e-07 |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 2.62e+09       |\n",
      "|    n_updates            | 60             |\n",
      "|    policy_gradient_loss | -3.24e-05      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 5.27e+09       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 126           |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 137           |\n",
      "|    total_timesteps      | 17408         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2504752e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.0           |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.6e+09       |\n",
      "|    n_updates            | 64            |\n",
      "|    policy_gradient_loss | -3.73e-05     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 7.02e+09      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 127           |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 144           |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.1851537e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.0           |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.76e+09      |\n",
      "|    n_updates            | 68            |\n",
      "|    policy_gradient_loss | -3.24e-05     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 9.4e+09       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 128           |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 19456         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8999057e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.0002669692  |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.92e+08      |\n",
      "|    n_updates            | 72            |\n",
      "|    policy_gradient_loss | -2.13e-05     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 4.43e+08      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 128           |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 159           |\n",
      "|    total_timesteps      | 20480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.152375e-06  |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 5.4240227e-06 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.29e+08      |\n",
      "|    n_updates            | 76            |\n",
      "|    policy_gradient_loss | -9.94e-05     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 4.62e+08      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 21504       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 6.21652e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.0         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.95e+08    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -6.98e-05   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 9.57e+08    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 127           |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 176           |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4238176e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.0           |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 8.61e+08      |\n",
      "|    n_updates            | 84            |\n",
      "|    policy_gradient_loss | -2.65e-05     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 1.67e+09      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 126            |\n",
      "|    iterations           | 23             |\n",
      "|    time_elapsed         | 186            |\n",
      "|    total_timesteps      | 23552          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 3.5355333e-07  |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -2.84          |\n",
      "|    explained_variance   | -1.1920929e-07 |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 1.32e+09       |\n",
      "|    n_updates            | 88             |\n",
      "|    policy_gradient_loss | -2.61e-06      |\n",
      "|    std                  | 1              |\n",
      "|    value_loss           | 2.67e+09       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 127          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.563519e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0010828376 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.4e+09      |\n",
      "|    n_updates            | 92           |\n",
      "|    policy_gradient_loss | -3.43e-05    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 3.03e+09     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 128           |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 199           |\n",
      "|    total_timesteps      | 25600         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7486163e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.0006672144  |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.84e+07      |\n",
      "|    n_updates            | 96            |\n",
      "|    policy_gradient_loss | -7.09e-05     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 1.83e+08      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 128           |\n",
      "|    iterations           | 26            |\n",
      "|    time_elapsed         | 206           |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2486784e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.0038144588  |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.22e+08      |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -3.88e-05     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 2.32e+08      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 129           |\n",
      "|    iterations           | 27            |\n",
      "|    time_elapsed         | 212           |\n",
      "|    total_timesteps      | 27648         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.6141365e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.0011351109  |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.53e+07      |\n",
      "|    n_updates            | 104           |\n",
      "|    policy_gradient_loss | -7.4e-05      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 1.43e+08      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 130           |\n",
      "|    iterations           | 28            |\n",
      "|    time_elapsed         | 219           |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8504874e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.0017722249  |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.27e+07      |\n",
      "|    n_updates            | 108           |\n",
      "|    policy_gradient_loss | -8.31e-05     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 1.63e+08      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 131          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 226          |\n",
      "|    total_timesteps      | 29696        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.940704e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0002347827 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.35e+08     |\n",
      "|    n_updates            | 112          |\n",
      "|    policy_gradient_loss | -0.000105    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 2.58e+08     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the agent (adjust the number of timesteps for quick feedback)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Train the agent\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2e5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mppo-snake-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/home/jjiang23/miniconda3/envs/WeScale/lib/python3.13/site-packages/stable_baselines3/ppo/ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/jjiang23/miniconda3/envs/WeScale/lib/python3.13/site-packages/stable_baselines3/common/on_policy_algorithm.py:300\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 300\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/home/jjiang23/miniconda3/envs/WeScale/lib/python3.13/site-packages/stable_baselines3/common/on_policy_algorithm.py:179\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# Convert to pytorch tensor or to TensorDict\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     obs_tensor \u001b[38;5;241m=\u001b[39m obs_as_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 179\u001b[0m     actions, values, log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n",
      "File \u001b[0;32m/home/jjiang23/miniconda3/envs/WeScale/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/jjiang23/miniconda3/envs/WeScale/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/home/jjiang23/miniconda3/envs/WeScale/lib/python3.13/site-packages/stable_baselines3/common/policies.py:654\u001b[0m, in \u001b[0;36mActorCriticPolicy.forward\u001b[0;34m(self, obs, deterministic)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;66;03m# Evaluate the values for the given observations\u001b[39;00m\n\u001b[1;32m    653\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_net(latent_vf)\n\u001b[0;32m--> 654\u001b[0m distribution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_action_dist_from_latent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_pi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m actions \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mget_actions(deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n\u001b[1;32m    656\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mlog_prob(actions)\n",
      "File \u001b[0;32m/home/jjiang23/miniconda3/envs/WeScale/lib/python3.13/site-packages/stable_baselines3/common/policies.py:694\u001b[0m, in \u001b[0;36mActorCriticPolicy._get_action_dist_from_latent\u001b[0;34m(self, latent_pi)\u001b[0m\n\u001b[1;32m    691\u001b[0m mean_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_net(latent_pi)\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, DiagGaussianDistribution):\n\u001b[0;32m--> 694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproba_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, CategoricalDistribution):\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;66;03m# Here mean_actions are the logits before the softmax\u001b[39;00m\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist\u001b[38;5;241m.\u001b[39mproba_distribution(action_logits\u001b[38;5;241m=\u001b[39mmean_actions)\n",
      "File \u001b[0;32m/home/jjiang23/miniconda3/envs/WeScale/lib/python3.13/site-packages/stable_baselines3/common/distributions.py:164\u001b[0m, in \u001b[0;36mDiagGaussianDistribution.proba_distribution\u001b[0;34m(self, mean_actions, log_std)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mCreate the distribution given its parameters (mean, std)\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    163\u001b[0m action_std \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mones_like(mean_actions) \u001b[38;5;241m*\u001b[39m log_std\u001b[38;5;241m.\u001b[39mexp()\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution \u001b[38;5;241m=\u001b[39m \u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/home/jjiang23/miniconda3/envs/WeScale/lib/python3.13/site-packages/torch/distributions/normal.py:59\u001b[0m, in \u001b[0;36mNormal.__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/jjiang23/miniconda3/envs/WeScale/lib/python3.13/site-packages/torch/distributions/distribution.py:41\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     Distribution\u001b[38;5;241m.\u001b[39m_validate_args \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     43\u001b[0m     batch_shape: torch\u001b[38;5;241m.\u001b[39mSize \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize(),\n\u001b[1;32m     44\u001b[0m     event_shape: torch\u001b[38;5;241m.\u001b[39mSize \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize(),\n\u001b[1;32m     45\u001b[0m     validate_args: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m ):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_shape \u001b[38;5;241m=\u001b[39m batch_shape\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_shape \u001b[38;5;241m=\u001b[39m event_shape\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the agent (adjust the number of timesteps for quick feedback)\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=int(2e5))\n",
    "# Save the trained model\n",
    "model_name = \"ppo-snake-v2\"\n",
    "model.save(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluation\n",
    "eval_env = Monitor(gymnasium.make(\"gymnasium_env/slither_world\"))  # Use Monitor for logging evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys ['foodList', 'mySnake', 'mySnakeBody']\n",
      "shapes {'foodList': (300,), 'mySnake': (2,), 'mySnakeBody': (200,)}\n",
      "dtypes {'foodList': dtype('float32'), 'mySnake': dtype('float32'), 'mySnakeBody': dtype('float32')}\n",
      "mean_reward=375705.00 +/- 584524.45\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WeScale",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
